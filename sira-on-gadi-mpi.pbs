#!/bin/bash
#PBS -N ramsey-EPN-mpi-run
#PBS -m be
#PBS -P w84
#PBS -q normalbw
#PBS -l walltime=12:00:00
#PBS -l ncpus=240
#PBS -l mem=1280GB
#PBS -l jobfs=400GB
#PBS -l storage=scratch/y57+scratch/n74+scratch/w84+gdata/w84
#PBS -j oe
#PBS -l wd

set -euo pipefail

# --- User configuration
ASSET="EPN_Yilgarn_microcomps_L3"
CODE_DIR="/scratch/y57/mr3457/code/sira"
MODELS_DIR="/scratch/y57/mr3457/code/_SYSTEM_MODELS/epn"
VENV="$HOME/venv/sira-v25"

# --- Environment setup
module load python3/3.11.7
module load openmpi/4.1.4
source "$VENV/bin/activate"

export OMP_NUM_THREADS=1
export MKL_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export NUMEXPR_NUM_THREADS=1
export NUMEXPR_MAX_THREADS=1

# Additional optimisations for large-scale HPC run
export MALLOC_MMAP_THRESHOLD_=131072
export MALLOC_TRIM_THRESHOLD_=131072
export OMP_WAIT_POLICY=PASSIVE

export SIRA_LOG_LEVEL=INFO
export SIRA_QUIET_MODE=0
# Use shared /scratch instead of node-local JobFS for MPI streaming
# JobFS is not shared across nodes - only one node's manifests would be visible
export SIRA_STREAM_DIR="/scratch/${PROJECT}/${USER}/sira_stream_${PBS_JOBID}"
mkdir -p "$SIRA_STREAM_DIR"

export SIRA_SAVE_COMPTYPE_RESPONSE=1
export SIRA_SAVE_COMPONENT_RESPONSE=0

# --- Performance tuning
# Optimised for large hazard file:
export SIRA_CHUNKS_PER_SLOT=1
# Fastest compression for large datasets:
export SIRA_STREAM_COMPRESSION=snappy
# Optimised row groups for large hazards (balance memory vs I/O):
export SIRA_STREAM_ROW_GROUP=524288
# Reproducible results:
export PYTHONHASHSEED=0
# Large hazard optimisation - avoid multiprocessing overhead:
export SIRA_MIN_HAZARDS_FOR_PARALLEL=100000

# --- HPC Optimisations

# Enable HPC optimisations for large-scale run
export SIRA_HPC_MODE=1

# Optimised batch size for <1000 components
export SIRA_MAX_BATCH_SIZE=1000

# Disable progress reporting for cleaner HPC logs
export SIRA_QUIET_MODE=1

# --- Run simulation
cd "$CODE_DIR"
LOGS_DIR="$CODE_DIR/logs"
mkdir -p "$LOGS_DIR"

printf '\n=== SIRA on Gadi ===\n'
printf 'Asset: %s\n' "$ASSET"
printf 'Working directory: %s\n' "$CODE_DIR"
printf 'Logs directory: %s\n' "$LOGS_DIR"
printf 'Stream directory: %s\n' "$SIRA_STREAM_DIR"

python - <<'PYCODE'
from sira.__main__ import safe_mpi_import
MPI, _, rank, size = safe_mpi_import()
if MPI is None:
    print('[x] MPI not available - job will exit')
    raise SystemExit(1)
print(f'[OK] MPI detected: rank {rank} of {size}')
PYCODE

# --- Main SIRA run - MPI backend with optimisations
echo "Starting SIRA (MPI) for large-scale simulation..."
echo "MPI ranks: $PBS_NCPUS"
echo "Start time: $(date)"

# Record start time for performance monitoring
START_TIME=$(date +%s)

# Bind MPI processes to cores for better performance
# Note: Detailed logs are written to <output_dir>/log.txt by the Python logger
mpirun -np "$PBS_NCPUS" --bind-to core --map-by core \
    python -m sira \
    -d "${MODELS_DIR}/${ASSET}/" -s \
    --parallel-backend mpi --stream-results

# Calculate and report execution time
END_TIME=$(date +%s)
DURATION=$((END_TIME - START_TIME))
echo "End time: $(date)"
echo "Total execution time: $((DURATION / 3600))h $((DURATION % 3600 / 60))m $((DURATION % 60))s"

# --- Fallback test with multiprocessing (optional)
# echo "Using multiprocessing backend..."
# python -m sira \
#     -d "${MODELS_DIR}/${ASSET}/" -s \
#     --parallel-backend multiprocessing --stream-results \
#     2>&1 | tee "$LOGS_DIR/sira_fallback.log"

# --- Simple post-run summary
CONFIG_FILE=$(find "${MODELS_DIR}/${ASSET}" -name "config*.json" | head -1)
if [ -n "$CONFIG_FILE" ] && [ -f "$CONFIG_FILE" ]; then
    OUTPUT_DIR_PATH=$(python -c '
import json, sys
try:
    with open(sys.argv[1], "r") as f:
        data = json.load(f)
    path = data.get("OUTPUT_DIR", "./output")
    if path.startswith("./"):
        path = path[2:]
    print(path)
except Exception:
    print("output") # Fallback
' "$CONFIG_FILE")
    OUTPUT_DIR="${MODELS_DIR}/${ASSET}/${OUTPUT_DIR_PATH}"
else
    OUTPUT_DIR="${MODELS_DIR}/${ASSET}/output"
fi

printf '\n=== Outputs ===\n'
printf 'Output directory: %s\n' "$OUTPUT_DIR"
if [ -d "$OUTPUT_DIR" ]; then
    ls -1 "$OUTPUT_DIR"
else
    printf '[x] Output directory not found\n'
fi

printf '\nStream directory contents:\n'
if [ -d "$SIRA_STREAM_DIR" ] && [ "$(ls -A "$SIRA_STREAM_DIR" 2>/dev/null)" ]; then
    echo "Stream directory size: $(du -sh "$SIRA_STREAM_DIR" | cut -f1)"
    echo "Number of files: $(find "$SIRA_STREAM_DIR" -type f | wc -l)"
    echo "Manifest files:"
    find "$SIRA_STREAM_DIR" -name "manifest*.jsonl" -exec wc -l {} \;
    echo "Sample files (first 20):"
    find "$SIRA_STREAM_DIR" -maxdepth 1 -type f -print | head -20
    echo "Chunk directories:"
    find "$SIRA_STREAM_DIR" -type d -name "chunk_*" | head -10
else
    printf '[x] No streaming files found\n'
fi

printf '\nLog tail:\n'
if [ -f "${MODELS_DIR}/${ASSET}/output/log.txt" ]; then
    tail -n 20 "${MODELS_DIR}/${ASSET}/output/log.txt"
else
    printf '[x] Log file not found\n'
fi

printf '\n=== Job finished ===\n'
